{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc7866-d22c-46b5-93f3-cf5009e9e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropped Image Code\n",
    "# lp = [600, 600]\n",
    "# hp= [0,0]\n",
    "\n",
    "# lp = [max(min(lp[0], int(lm.x * resolution[1]))-2, 0),\n",
    "#     max(min(lp[1], int(lm.y * resolution[0]))-1, 0)]\n",
    "\n",
    "# hp = [min(max(hp[0], int(lm.x * resolution[1]))+1, resolution[1]),\n",
    "#     min(max(hp[1], int(lm.y * resolution[0]))+1, resolution[0])]\n",
    "\n",
    "\n",
    "# cropImg = img[lp[1]:hp[1], lp[0]:hp[0]]\n",
    "# cropImg = cv2.resize(cropImg, (300, 300))\n",
    "# cv2.imshow(\"hand\",cropImg)\n",
    "\n",
    "# cropImg = cv2.resize(cropImg, (30,30))\n",
    "# cropImg = cv2.cvtColor(cropImg, cv2.COLOR_BGR2GRAY)\n",
    "# cropImg = cv2.equalizeHist(cropImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e619ce-62f7-4da9-94f1-9fadeab2e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie Photos\n",
    "# for classification in classifications:\n",
    "#     handset = []\n",
    "#     photoset = []\n",
    "        \n",
    "#     photo_files = os.listdir(f\"Resources/{classification}/photo/\")[1:]\n",
    "#     for photo in photo_files:\n",
    "#         img = cv2.imread(f\"Resources/{classification}/photo/{photo}\", 0)\n",
    "#         photoset.append([np.array(img), np.eye(4)[classes[classification]]])\n",
    "#     np.save(f\"Resources/{classification}/{classification}_photos.npy\", photoset)\n",
    "\n",
    "#     hand_files = os.listdir(f\"Resources/{classification}/hand/\")[1:]\n",
    "#     for hand in hand_files:\n",
    "#         img = np.load(f\"Resources/{classification}/hand/{hand}\", allow_pickle=True)\n",
    "#         handset.append([np.array(img), np.eye(4)[classes[classification]]])\n",
    "#     np.save(f\"Resources/{classification}/{classification}_hands.npy\", handset)\n",
    "\n",
    "# masterhand = np.load(\"Resources/yes/yes_hands.npy\", allow_pickle=True)\n",
    "# masterphoto = np.load(\"Resources/yes/yes_photos.npy\", allow_pickle=True)\n",
    "\n",
    "# for classification in classifications[1:]:\n",
    "#     currenthands = np.load(f\"Resources/{classification}/{classification}_hands.npy\", allow_pickle=True)\n",
    "#     currentphotos = np.load(f\"Resources/{classification}/{classification}_photos.npy\", allow_pickle=True)\n",
    "    \n",
    "#     masterhand = np.concatenate((masterhand, currenthands))\n",
    "#     masterphoto = np.concatenate((masterphoto, currentphotos))\n",
    "\n",
    "# np.save(\"Resources/photos_master_set.npy\", masterphoto)\n",
    "# np.save(\"Resources/hands_master_set.npy\", masterhand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
